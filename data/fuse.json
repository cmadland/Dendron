{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title"},{"path":["body"],"id":"body","weight":1,"src":"body"}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Literature","n":1},"1":{"v":"# Colin Madland\n\nUsing this site to build a networked literature repository\n## Lookup\n\nThis section contains useful links to related resources.\n\n- [Getting Started Guide](https://link.dendron.so/6b25)\n- [Discord](https://link.dendron.so/6b23)\n- [Home Page](https://wiki.dendron.so/)\n- [Github](https://link.dendron.so/6b24)\n- [Developer Docs](https://docs.dendron.so/)\n","n":0.189}}},{"i":2,"$":{"0":{"v":"Dissertation","n":1}}},{"i":3,"$":{"0":{"v":"Publication","n":1}}},{"i":4,"$":{"0":{"v":"Miller","n":1}}},{"i":5,"$":{"0":{"v":"millerLeveragingCSCLTechnology2015","n":1},"1":{"v":"\nhttp://hdl.handle.net/1828/6582\n\n## Abstract\n\nCollaboration is a vital skill in today’s knowledge economy. Regrettably, many learners lack the regulatory skills required for complex collaborative tasks. In particular, groups struggle to construct shared task perceptions of collaborative tasks on which to launch engagement. Thus, the purpose of this dissertation was to examine how computer supported collaborative learning (CSCL) tools can be leveraged to support shared task perceptions for regulating collaboration. Because investigating this process brings forth a wide array of methodological challenges, a second purpose of this dissertation was to explore how CSCL tools can be used as a methodological solution for capturing this process. Towards this end, research unfolded across one conceptual paper and two empirical studies: (a) Miller & Hadwin (2015a) extended work conceptualizing self-, co-, and shared-regulation in successful collaboration and drew on this theoretical framework to propose ways in which CSCL tools can be designed to support and research regulation of collaboration; (b) Miller, Malmberg, Hadwin, & Järvelä (2015) investigated the processes that contributed to and constrained groups’ construction of shared task perceptions in a CSCL environment in order to inform further refinement of supports; (c) Miller & Hadwin (2015b) examined the effects of tools providing different levels of individual and group support on construction of shared task perceptions and task performance. Together, findings revealed the potential of blending pedagogical tools to support shared task perceptions with research tools for examining and understanding regulation. In particular, findings evidenced shared task perceptions to be a complex and challenging social phenomenon and shed light on ways in which CSCL tools may prompt and promote this process. In addition, data generated by learners as they interacted with CSCL supports created valuable opportunities to capture shared task perceptions as they unfolded in the context of meaningful collaborative tasks across the individual and group level.\n","n":0.058}}},{"i":6,"$":{"0":{"v":"Info","n":1},"1":{"v":"\nhttps://drive.google.com/drive/folders/0B-bv3P4k4FkEOUpJRDBEa3I2Umc?ths=true&resourcekey=0-3CUGSHT9EBLxQoclHY_eAg\n\n### How do you write the proposal? Where does the proposal break off into 3 studies? at the RQ level? purpose?\n- 2-papers for candidacy over a month, very general questions.\n- one theoretical and one methodological\n- M ended up collecting data, and completing the studies, then writing a proposal for which papers to include in the diss\n- defended proposal very late in the process\n- proposal was an overview, not much lit b/c it was covered in candidacy papers, rather built from candidacy papers\n- 3 papers built off each other so harder to write a specific proposal for 2nd and 3rd paper\n- dissertation was a shortened version of candidacies, tightened\n- summarized implications\n- main idea is to create a meta-leve proposal\n- studies can be RQ\n- could be MM over-arching design, lots of variation\n- proposal should be overarching methods for all three\n\n### Concurrent? Consecutive? Rules or guidelines?\n- M did it consecutive\n- 1st was theoretical, submitted to J\n- 2nd, was big idea, but they didn't know how it worked in the classroom, qualitative exploration\n- once those were established, 3rd was more quantitative. \n- all three were consecutive\n- if you have to do them consecutively, they can take a long time\n- could be that you do them concurrently\n- no real guidleines\n\n[Link from chat](https://jultika.oulu.fi/Record/isbn978-951-42-6330-9) or [persistent link](http://urn.fi/urn:isbn:9789514263309)\n- U of Oulu; 5-7 papers\n- questions around a big idea, less tightly connected\n- papers have to conceptually contribute to the ideas\n\n### Seems that the guiding principle should be around the Problem\n- there needs to be something holding it all together\n- no hard and fast set of guidelines\n- big theoretical and methodological sections\n\n### Which version?\n- permission from journal to use pre-pub\n- tricky, one was in submission during the process\n- M withheld a paper from UVic for a year to see where it would go...problem if the paper changes while under review.\n- no time to think about copyright and publications elsewhere...last screen in dissertation submission\n\n- required to have one accepted for publication and all submitted at time of defense\n\n### Would you do it again?\n- yes, definitely\n- missed out on longest lit review ever in monograph\n- more practical skills\n- writing a monograph is different from writing for a journal\n- once you submit, you get lots of honest feedback from peer review\n- 3 things to publish rather than a monograph\n- better prepared for SSHRC grant\n- able to think across bigger research project with smaller components\n\n### Take longer\n- it can with revisions and esp if consecutive\n- hard to judge as m was working full time\n- Proposal to defense was [edited out]\n\n### 3 ethics apps?\n- 1st paper was theoretical\n- 2nd was in Finland under existing ethics\n- 3rd was under existing ethics at UVic\n- so no ethics for diss\n\n### Lit review?\n- not as in-depth as for a monograph\n- challenging to work with other universities\n\n### Writing final analysis? create overarching paper?\n- wide variety\n- 3 topics/papers\n- summarized the papers, then main findings, biggest findings across all three papers, typical journal article structure\n\n- M's proposal was very specific b/c she had done so much ahead of time\n- difficult to squish 3-paper diss into template (3 journal articles all have different running heads...)\n- \n","n":0.044}}},{"i":7,"$":{"0":{"v":"ThreePapersPhD","n":1},"1":{"v":"\n## The 'three papers' PhD thesis: a guide for the perplexed\n\nAthens University of Economics and Business\n\n\n \nhttps://www.dept.aueb.gr/sites/default/files/deos/3_paper_phd_guide.pdf\n\n- 3 separate, publishable papers\n- normal journal article length (5000-10000 words)\n- free-standing and independent, but on related themes\n- normally preceded by short introduction\n- may include lit review but not necessary\n\n1. Intro and background\n2. first paper\n3. second paper\n4. third paper\n5. conclusions and implications\n\n- usually 5 chapters\n- 150 A4 pages (35000 words) plus appendices, although appendices are commonly appended to each paper, rather than the thesis\n\n### FAQ\n\n- Do papers need to be published?\n  - no, they need to be publishable, although publication is *prima facie* evidence of publishability\n- co-authorship?\n  - must be substantially the learner's work, so first author\n- Lit review?\n  - format involves jettisoning conventional ideas, such as a 'lit review' chapter\n  - each article contains a lit review, but of an appropriate length for a journal article\n  - that said, some people have included a lit review chapter\n","n":0.081}}},{"i":8,"$":{"0":{"v":"GuidelinesDissertationThree","n":1},"1":{"v":"\n## Guidelines for the Dissertation of Three Publishable Papers\n\nhttps://fsph.iupui.edu/doc/student-portal/Guidelines_for_Dissertation_of_Three_Papers.pdf\n\n|   | Conventional Dissertation | 3-paper Dissertation |\n|---|:---:|:---:|\n| Introduction and outline of the problem | ✔️  |   |\n| Introduction to the overall topic |   | ✔️ |\n| Conceptual or theoretical framework | ✔️  | ✔️  |\n| Lit review | ✔️  | Included in 3 papers |\n| Methodology | ✔️  | Included in 3 papers |\n| Results / findings | ✔️  | Included in 3 papers |\n| 3 separate, publishable papers of normal journal article length related to the overall theme |   |  ✔️ |\n| Summary, Interpretations, conclusions, recommendations for policy or future research | ✔️ | Concluding scholarly discussion of the implications of the integrate findings |\n| Resources | ✔️  | Included in 3 papers |\n| Appendices | optional | optional |\n\n### Is the proposal defense the same?\n- yes, cmte approves selection of 3-paper option at proposal defense\n- at final oral defense, cmte will judge the quality and acceptability of the papers and must agree that they are of sufficient scholarly quality and scientific merit to be published in refereed journals in your discipline.\n\n\n### Do papers need to be published before submitting dissertation?\n- no, they must be publishable \n- may be submitted prior to defense only with permission of the cmte\n- after defense, all papers to be submitted to refereed journals\n- evidence of manuscript submission is required prior to final dissertation signatures\n\n### Primary authorship\n- cmte members listed if they have contributed written feedback to the papers\n\n### Lit review?\n- no, included in each of the three papers\n- align with specifications of the journal\n\n### Publish before or after graduation?\n- depends...papers can be applied to T&P if they are published after appointment to faculty position\n- but students will be more competitive if they have more pubs\n\n### Format?\n- consult with cmte\n- use format of specific journals","n":0.058}}},{"i":9,"$":{"0":{"v":"Assessment","n":1}}},{"i":10,"$":{"0":{"v":"Online","n":1}}},{"i":11,"$":{"0":{"v":"Students","n":1}}},{"i":12,"$":{"0":{"v":"spiveyClassroomOnlineAssessment2014","n":1},"1":{"v":"\n#learner.perspective \nSpivey, M. F., & McMillan, J. J. (2014). Classroom Versus Online Assessment. Journal of Education for Business, 89(8), 450–456. <https://doi.org/10/gn9qtv>\n","n":0.218}}},{"i":13,"$":{"0":{"v":"khanOnlineAssessmentsExploring2019","n":1},"1":{"v":"\n#methods.qualitative #learner.perspective\n\n[[assessment.online.students.spiveyClassroomOnlineAssessment2014]]\n\nKhan, S., & Khan, R. A. (2019). Online assessments: Exploring perspectives of university students. *Education and Information Technologies, 24*(1), 661–677. <https://doi.org/10/gkpz6g>\n\n## Abstract\n\n> The United Arab Emirates is committed to integrating technology into higher education. In this study the researchers aim to explore the perspectives of university students on online assessments. An understanding of students’ views can help identify obstacles and promotors in embracing online assessments at the undergraduate level. The social constructivist epistemology has been used in this qualitative study to understand students’ preferences, apprehensions and acceptance of online assessments. Semistructured focus group discussions were carried out after recruiting 41 university students, using convenience and snowball sampling methods. Thematic content analysis was applied to the data. This study highlighted that students did not comprehend the need for online assessments. Concerns regarding technological incompetence of students and teachers alongside distrust in the technology infrastructure were stressed. Students felt online assessments were restrictive for the science courses and had resulted in falling grades; probably due to the increasing dependence on multiple choice questions. Students also expressed the importance of constructive, timely and personalized feedback. Students need to be convinced of the usefulness of the transition to online assessment before they agree with it. It is evident through this study that student acceptance would increase with a gradual transition towards online assessments alongside technological training for both students and faculty. Active individualized interaction with instructors is important to students, furthermore preferences and concerns emphasized by students should be addressed to successfully integrate online assessments into higher education.\n\n- ~25% of the federal budget is allocated to education in UAE","n":0.061}}},{"i":14,"$":{"0":{"v":"Highered","n":1}}},{"i":15,"$":{"0":{"v":"Digital","n":1}}},{"i":16,"$":{"0":{"v":"bearmanReimaginingUniversityAssessment2020","n":1}}},{"i":17,"$":{"0":{"v":"ch2","n":1},"1":{"v":"\n# New Directions for Assessment in a Digital World\nMargaret Bearman, David Boud, and Rola Ajjawi\n\n## Abstract \n\nAssessment exists within a series of pedagogical, administrative and technological legacy practices. It tends therefore to reflect the needs and concerns of a previous time. However, this does not align with a digitally enabled world with rapidly expanding information and an increasingly dynamic view of knowledge. This chapter explores how to reimagine assessment in a time of digital change. Firstly, it investigates how assessment designs can draw on technology to move beyond the status quo, providing an example of a programmatic e-portfolio. Next, it introduces the idea that assessments should enable graduates to work in the digital world. This is discussed through an illustration of how students can build effective digital personas, including social media profiles, within their assessments. Finally, it looks to the inter-relationship between assessment and knowledge in a digital world, suggesting co-construction as a guiding principle. Often assessment is overlooked in discussions of educational technology. Reimagining university assessment is a key way to make teaching and learning applicable to a digital world.\n\n## p7\n\n## Introduction\n\n> Traditions cast long shadows. No matter when you were educated, you would find many aspects of today’s typical university assessments familiar, if not identical, to those held within your alma mater.\n\n## p8\n\n> So it remains curious that even though universities may use digital technologies to conduct assessment, it is often in the same form as in previous generations, albeit more efficiently, at distance and at scale.\n\n> The digital technologies that underlie these changes have much to offer university assessment. However, as described, traditions are remarkably persistent and new tools have tended to reinforce the same educational practices (- Selwyn 2014, 2016).\n\n- Selwyn, N. (2014). Digital technology and the contemporary university: Degrees of digitization. London: Routledge.\n- Selwyn, N. (2016). Is technology good for education? Cambridge: Polity.\n\n> The dominant modes of university assessment remain much as they were: demonstrations of knowledge, such as quizzes, tests or essays, which can be easily compared and graded. In a time where it is easy to access information rapidly and accurately, our assessments appear to be somewhat missing the point. They too often require a high degree of recall and offer little opportunity for student input or choice. Our overall impression is, in higher education, the digital has locked in an old set of ideas about assessment.\n\n> However, there is little discussion regarding how these contemporary views of assessment can mesh with the now ubiquitous digital technologies, educational or otherwise. Assessment is often overlooked in educational technology conversations despite its pivotal role within the academy. As we explore later, institutions and educators reveal their values both by what is assessed and how (Knight 1995). We suggest that significant questions remain largely unaddressed: How can technology support forms of assessment that emphasise learning? How can assessments support living and working in a digital era, with its networked and rapid access to both people and information?\n\n## p9\n\n## The Need to Reimagine\n\n> So, higher education cannot avoid digital technologies, irrespective of whether deliberate attempts to harness technology to improve education are successful.\n\n> In his 2014 book, Digital Technology and the Contemporary University: Degrees of Digitisation, Selwyn interrogates the current status of technology within the university. He writes: “the pessimistic commentator [accepts] that digital technology is not bringing about the changes and transformations that many people contend…” (p. 18). He calls for “the very difficult conversations that need to take place about what digital higher education is, and what digital higher education should be.” From Selwyn’s perspective, technology is not neutral: it serves a variety of different and often competing agendas. He notes, as we have, that digital technologies tend to maintain the status quo. Most of the book dissects the often grim realities of digital technologies in our universities and outlines a range of ways in which administrative and educational technologies “reproduce long-standing and deep-rooted structures and arrangements” (p. 141). However, in closing, Selwyn suggests we need to reimagine higher education in this digital era. He calls for changes in how we talk about educational technology, the physical spaces surrounding technologies, and the need for guiding principles which outline moral rules of engagement.\n\n>The second scholarly work of interest is Barnett and Bengtsen’s 2017 paper: Universities and Epistemology: From a Dissolution of Knowledge to the Emergence of a New Thinking. In contrast to Selwyn’s pessimistic stance, the authors “argue that an optimistic university is a university-in-the-world and thinks the future from the world.”\n\n## p10\n\n> If the very notions of truth and knowledge have changed, then this necessarily impacts upon institutions whose core purpose is knowledge production.\n\n## Reimagining the Status Quo","n":0.036}}},{"i":18,"$":{"0":{"v":"Chapter 1","n":0.707},"1":{"v":"\n#assessment.digital\nDawson P., Ajjawi R., Bearman M., Boud D., Tai J. (2020) Introduction. In: Bearman M., Dawson P., Ajjawi R., Tai J., Boud D. (eds) [Re-imagining University Assessment in a Digital World.](https://doi-org.ezproxy.library.uvic.ca/10.1007/978-3-030-41956-1_1) The Enabling Power of Assessment, vol 7. Springer, Cham. \n\n- catalysed at the 2017 symposium at the Centre for Research on Assessment and Digital LEarning (CRADLE)\n- challenge to 'fundamentally re-imagine the intersection of assessment and digital learning in higher education.\n\n> While the authors in this book take a range of views about assessment and focus on various purposes or aspects, these align with the broadest view: assessment as making judgements about what someone is capable of, based on some sort of demonstration or product\n\n> The digital world offers a range of technologies that can enable us to do things we’ve always wanted to do with assessment at a massive scale. It also enables us to assess differently, or make sense of masses of data to understand the efficacy of existing approaches.\n> The digital world also poses fundamental challenges not just to how we assess, but to what we assess.\n\n> Assessment in a digital world is thus a broader concept than the narrower concept of ‘e-assessment’ that tends to occupy the intersection between technology and assessment. E-assessment is largely concerned with technologized assessment, and at its best it leverages what new technologies can do to enable new forms of assessment that are better for learning and judging what students can do. While there is benefit in making assessment digital, we think that there are much greater opportunities and challenges posed by the digital world for assessment. Some of these may not even involve technologized assessment at all; instead they may involve preparing learners for tasks that are distinctly human. \n\n","n":0.059}}},{"i":19,"$":{"0":{"v":"fernandesAssessmentHigherEducation2022","n":1},"1":{"v":"\n#AEHE #hopper #sampling.non-probablistic #methods.mixed\nFernandes, E. L., & Flores, M. A. (2022). Assessment in higher education: Voices of programme directors. *Assessment & Evaluation in Higher Education, 47*(1), 45–60. https://doi.org/10/gpbbh8\n\n## Abstract\nThis study examines the views of assessment of programme directors at a Portuguese public university (n = 60). Data were collected through a questionnaire which included closed and open-ended questions. The participants hold different professional categories and come from medical and health sciences, exact sciences, engineering and technology, social sciences and humanities. Data suggest the use of a variety of assessment methods, through a mix of learner-centred and traditional methods. The year of study, the type of course, the nature of the programmes and the institutional regulations were identified by the programme directors as factors that may influence the selection of the assessment methods. The participants considered assessment practices to be in general adequate, but there is room for improvement, namely through an integrated and interdisciplinary approach.\n## Introduction\n\n## The study\n### Research instrument\n### Participants\n### Analyses\n\n## Findings\n### Bologna Process 20 years later: what kind of changes?\n### Assessment practices\n### The place of assessment\n## Conclusions","n":0.075}}},{"i":20,"$":{"0":{"v":"Foundation","n":1}}},{"i":21,"$":{"0":{"v":"pellegrinoKnowingWhatStudents2001","n":1},"1":{"v":"\nPellegrino, J. W., Chudowsky, N., & Glaser, R. (2001). *Knowing What Students Know: The Science and Design of Educational Assessment.* National Academies Press. https://doi.org/10.17226/10019\n\n\n #assessment.assessment-triangle #assessment.context-dependent #reasoning #evidence #assessment.alignment\n\n---\n\n## Assessment Triangle\n![Assessment Triangle](assets/assessment-triangle.png)\n\nThe NRC models assessment as a triangle composed of three interdependent components of any assessment (Figuintro):  *cognition*, or a model of the domain to be learned; *observation*, or the performance task learners will complete to demonstrate their competence; and an *inference* or *interpretation* of the data produced by the observation. The interdependent nature of the three components requires that both the observation and interpretation components be grounded in the nature of the cognitive model of the domain. For example, if the domain of knowledge is, broadly speaking, statistics, then the observation, or performance task, must elicit responses which require the examinee to demonstrate competence in statistics [@gerritsen-vanleeuwenkampAssessmentQualityTertiary2017]. If the performance task requires the ability to speak Icelandic, a different cognitive domain, then a Swahili-speaking examinee's responses will not be representative of their ability in statistics, but rather their lack of ability to speak Icelandic. Consequently, the examiner will have no basis for making an inference about the examinee's statistical ability; in other terms, the inference would be invalid because the performance task is not aligned with the cognitive model (see also [@biggsWhatStudentDoes1999]). [[assessment.foundation.biggsWhatStudentDoes1999]]\n\n\n### Cognition\n\n### Observation\n\n### Interpretation\n\n### p 25\n\n> This evolutionary process is described in more detail in Chapters 3 and 4. As Mislevy (1993, p. 19) has noted, “It is only a slight exaggeration to describe the test theory that dominates educational measurement today as the application of 20th century statistics to 19th century psychology.” Although the core concepts of prior theories and models are still useful for certain purposes, they need to be augmented or supplanted to deal with newer assessment needs.\n\n### p43 \n\n> reasoning from evidence\n\n\n### p112\n> a process of drawing reasonable inferences about what students know on the basis of evidence derived from observations of what they say, do, or make in selected situations \n\n","n":0.055}}},{"i":22,"$":{"0":{"v":"biggsWhatStudentDoes1999","n":1},"1":{"v":"#assessment.alignment\n","n":1}}},{"i":23,"$":{"0":{"v":"Socialmedia","n":1}}},{"i":24,"$":{"0":{"v":"Twitter","n":1}}},{"i":25,"$":{"0":{"v":"katsarosReconsideringTweetsIntervening2021","n":1},"1":{"v":"<https://arxiv.org/abs/2112.00773>\n","n":1}}},{"i":26,"$":{"0":{"v":"hagerBroadcasterJodyVance2021","n":1},"1":{"v":"\n#jodyvance\n\nhttps://www.theglobeandmail.com/canada/british-columbia/article-broadcaster-jody-vance-feels-relief-after-suspect-charged-following/\n\n","n":1}}},{"i":27,"$":{"0":{"v":"pazurekSocialMediaConnected2021","n":1},"1":{"v":"\nPazurek, A. (2021). *Social Media for Connected Learning and Engagement in Online Education.* In B. Hokanson, M. Exter, A. Grincewicz, M. Schmidt, & A. A. Tawfik (Eds.), *Learning: Design, Engagement and Definition* (pp. 137–145). Springer International Publishing. https://doi.org/10.1007/978-3-030-85078-4_11\n\n# Abstract\n\n#socialmedia #spark #connected #edci338\n\n\n> This chapter presents the findings of a phenomenological research study that explored the use of social media in an online college course and its impact on learners’ experiences and feelings of engagement. Findings suggest that social media has the potential to positively impact learner engagement with instructional support and when it is elevated from merely an entertainment source to a productive source for connected learning. This includes uses for communication as well as creative expression within and beyond the class.\n\n> Global market research suggests that social media use remains one of the most popular online activities around the world, with worldwide adoption reportedly estimated at 4.2 billion users (DataReportal, 2021), representing approximately 54% of the world population. In the United States, traditional college-age students are using social media now more than ever. According to the Pew Research Center (2019), approximately 70% of American adults use at least one social media platform for interpersonal connections, access to news content, sharing information, and entertainment, with the highest use among young adults in the 18–29-year-old age range.\n\n> Dabbagh and Kitsantas (2012) broadly define social media as \"a variety of networked tools or technologies that emphasize the social aspects of the Internet as a channel for communication, collaboration, and creative expression\" (p. 3).\n\n> As these technologies continue to proliferate, many college students are actively involved in participatory cultures (Jenkins, 2009) \n\n### p138\n\n> This phenomenological study investigated the lived experience of engagement when using social media as a learning resource during an online college course. The purpose of this research is to help online instructors and designers in higher education better understand how learners experience engagement when learning online with social media. Connected learning served as a conceptual framework to critically analyze meaningful connections within the learning experience and to address the following research questions: What is it like to experience engagement when using social media for learning in an online college course? And how do various elements of learning with social media influence learners’ feelings of engagement?\n\n> To maximize learner engagement, more open conceptions of learning must be considered. The ubiquity of technology is now shaping learning as mobile, open, and networked. Learning is not just confined to classrooms or formal education programs. Rather, it is an everyday occurrence that happens lifelong and life wide, formally and informally, both inside and outside of school. So it must be framed as much more fluid than traditional, formal conceptions of education often imply. The connected learning framework has been proposed in seminal research by Ito et al.\n\n### p139\n> (2013) as a learning, design, and technology model based on such open, inclusive, and fluid conceptions of learning. It focuses on illuminating diverse learning pathways that move across formal and informal settings to transform the very nature of learning, including what it means, how it is defined, how it occurs, and where it takes place.\n\n> Connected learning environments weave together learning activities that are interest-driven, peer-supported, and academically oriented (Ito et al., 2013). Thus, connected learning experiences prioritize and leverage learners’ personal interests and peer networks as a means to open up new opportunities for learning.\n\n## Research Findings\n### p142\n\n> According to participant narratives drawn from interviews, reflection blog postings, emails, and other digital artifacts generated for class activities, engagement in social media feels focused, purposeful, and self-driven. It often develops naturally as students gain more comfort and familiarity with this method of learning and the use of different platforms. When using social media in an online course, it doesn’t usually feel engaging right away and can actually feel stressful and unfamiliar. Participants often commented that they initially experienced some tension and discomfort with this new approach to learning online. Early in their experience they remarked that they preferred to use learning strategies like discussion forums in a traditional Learning Management System because this medium was often used in their previous online courses. However, for every participant, engagement evolved over time as more familiarity was established and comfort was developed. It continued to heighten as the course went along and as they discovered new ways of communicating and participating with it through interactions with the instructor and classmates.\n\n### p143\n\n> Findings also suggest that engagement when learning with social media may also feel creative, unique, and artistic. This was also framed by participants as a personal rather than a social attribute, especially in class activities when social media was used for more than just relaying or sharing information. When students were encouraged to create something new like a web page or infographic using Adobe Spark based on a course topic, this was perceived to be much more engaging and meaningful.\n\n> Participants also indicated that formal requirements for class activities, including rubrics or exact specifications for a task or project, often felt limiting, forced, and even intimidating, which diminished feelings of engagement.\n\n> for some class projects students were able to pursue a topic related to their own interests and create a digital artifact of their choice (e.g., a web page, video, or blog post) to demonstrate their understanding and skills. However, some participants also indicated that more freedom to make choices about what they wanted to do or how they could do it sometimes also felt very overwhelming and intimidating.\n\n> It was also disengaging when there was too much information or too many things to read and respond to. In these situations, participants often weren’t sure how to wade through and make sense of an overabundance of resources. They stated that instructor guidance and help in these instances was necessary and beneficial.\n\n> In summary, findings indicate that social media has the potential to positively impact learner engagement when integrated with connected learning principles and supported with pedagogical guidance. For example, instructor modeling and examples created by the instructor and shared with students were especially helpful in demonstrating how particular social media tools can be used for communication, collaboration, and creativity. Nearly all participants described the important influence of these supportive design elements, especially early in the course.\n\n## Implications\n\n### p144\n\n> The findings of this study suggest that the use of social media for learning in online college courses has the potential to be more engaging and connections are more meaningful when social media use is elevated to be a source for interaction among classmates, leveraging personal interests, sharing new ideas, and creative expression within and beyond the class.\n\n> More research in this area is necessary, but these findings support that intentionally integrating social media using connected learning principles may also be valuable in establishing coherence between where and how people interact, communicate, and learn.\n\n> The study also supports a call for a re-envisioning of what online course designs can include beyond traditional conventions and to illustrate how meaningful it may be to open up possibilities for the potential that social media holds for learning, both during a formal course and beyond.\n\n## Commentary\n\nPazurek (2021) engaged in a phenomenological exploration of the lived experiences of learners taking an undergraduate course on social media and connected learning. They noted factors that may have led students to feel more engaged in the course.\n\nThey noted that learners often initially felt overwhelmed and uncomfortable engaging in unfamiliar tools as opposed to the familiar context of the learning management system's forums. As learners became more familiar with social networking tools, however, they began to engage more deeply with their fellow learners and instructor.\n\nLearners felt more creative and artistic while engaging with social media tools and that their work was more meaningful.\n\nThey reported that typical formal structures of courses like rubrics and precise specifications felt limiting and reduced their level of engagement.\n\nLearner choice was seen as both positive and negative in that they had freedom to pursue their own interests, but that having too many choices could be overwhelming.\n\nSocial media has the potential to positively impact learner engagement, especially when coupled with high levels of instructor involvement and support.\n\n","n":0.027}}},{"i":28,"$":{"0":{"v":"gallantDirtyWorkCleaning2022","n":1},"1":{"v":"\n#edci338\n\nhttps://thewalrus.ca/clean-online-reputation/ \n\n","n":0.707}}},{"i":29,"$":{"0":{"v":"funkIndigenousAuthorshipOpen2020","n":1},"1":{"v":"\n#edci338\n","n":1}}},{"i":30,"$":{"0":{"v":"brownEthicalUseTechnology2020","n":1},"1":{"v":"\n#edci338\n\nhttps://openeducationalberta.ca/educationaltechnologyethics/\n","n":1}}},{"i":31,"$":{"0":{"v":"Highered","n":1}}},{"i":32,"$":{"0":{"v":"Digital","n":1}}},{"i":33,"$":{"0":{"v":"selwynDigitalTechnologyContemporary2014","n":1},"1":{"v":"\nSelwyn, N. (2014). Digital Technology and the Contemporary University: Degrees of digitization (1st ed.). Routledge. https://doi.org/10.4324/9781315768656\n\n","n":0.25}}},{"i":34,"$":{"0":{"v":"barnettUniversitiesEpistemologyDissolution2017","n":1},"1":{"v":"\nBarnett, R., & Bengtsen, S. (2017). Universities and Epistemology: From a Dissolution of Knowledge to the Emergence of a New Thinking. Education Sciences, 7(1), 38. https://doi.org/10/gjngg4\n","n":0.196}}},{"i":35,"$":{"0":{"v":"Cognitiveload","n":1}}},{"i":36,"$":{"0":{"v":"swellerCognitiveLoadTheory1994","n":1},"1":{"v":"\n# Abstract\n\n> This paper is concerned with some of the factors that determine the difficulty of material that needs to be learned. It is suggested that when considering intellectual activities, schema acquisition and automation are the primary mechanisms of learning. The consequences of cognitive load theory for the structuring of information in order to reduce difficulty by focusing cognitive activity on schema acquisition is briefly summarized. It is pointed out that cognitive load theory deals with learning and problem solving difficulty that is artificial in that it can be manipulated by instructional design. Intrinsic cognitive load in contrast, is constant for a given area because it is a basic component of the material. Intrinsic cognitive load is characterized in terms of element interactivity. The elements of most schemas must be learned simultaneously because they interact and it is the interaction that is critical. If, as in some areas, interactions between many elements must be learned, then intrinsic cognitive load will be high. In contrast, in different areas, if elements can be learned successively rather than simultaneously because they do not interact, intrinsic cognitive load will be low. It is suggested that extraneous cognitive load that interferes with learning only is a problem under conditions of high cognitive load caused by high element interactivity. Under conditions of low element interactivity, re-designing instruction to reduce extraneous cognitive load may have no appreciable consequences. In addition, the concept of element interactivity can be used to explain not only why some material is difficult to learn but also, why it can be difficult to understand. Understanding becomes relevant when high element interactivity material with a naturally high cognitive load must be learned.\n\n## Notes\n\n### p296\n> There are two critical learning mechanisms: schema acquisition and the transfer of learned procedures from controlled to automatic processing. It will be argued that intellectual mastery of any subject matter is overwhelmingly dependent on these two processes.\n\n### Schemas\n> A schema is a cognitive construct that organizes the elements of information according to the manner with which they will be dealt. An early discussion of schemas was presented by Bartlett (1932). He demonstrated that what is remembered is only partly dependent on the information itself. Newly presented information is altered so that it is congruent with knowledge of the subject matter. Knowledge of subject matter is organized into schemas and it is these schemas that determine how new information is dealt with.\n\n### p297\n> In summary, knowledge and intellectual skill based on knowledge is heavily dependent on schema acquisition. Schemas provide the basic unit of knowledge and through their operation can explain a substantial proportion of our learning-mediated intellectual performance.\n\n### Automation of Intellectual Operations\n\n\n> Schemas tend to be discussed as though schema acquisition results in dichotomous states: a person either has or has not acquired schemas. In fact, few intellectual skills are acquired in this manner. When something is first learned, the ability to use it is likely to be severely constrained. A student who has just learned how to multiply out the denominator of an equation cannot do so easily or fluently. He or she can do so only with considerable thought and effort. Similarly, an educated adult can read text without conscious effort whereas a child who has been learning for only a few years, while being able to read, will only be able to do so with considerable effort.\n\n### What is the Function of Learning?\n\n> From the above analysis, one function of learning is self-evident: to store automated schemas in long-term memory.\n\n### p299\n> While storing information in long-term memory is an obvious function of learning, it may not be the only one. The two learning mechanisms discussed above, schema acquisition and automation, share one intriguing characteristic. Both have the effect o{ substantially reducing working memory load.\n\n> Schemas effectively increase the amount of information that can be held in working memory by chunking individual elements into a single element. \n\n> Automation also has a significant effect on working memory. It permits working memory to be by-passed. Processing that occurs automatically requires less working memory space and as a consequence, capacity is freed for other functions.\n\n### Facilitating Learning and Problem Solving\n\n\n> If schemas are critical to learning and problem solving, what conditions are most likely to facilitate acquisition? Over the last decade or so, cognitive load theory (Sweller, 1988, 1989) has been used to investigate several instructional techniques. The theory suggests that instructional techniques that require students to engage in activities that are not directed at schema acquisition and automation, frequently assume a processing capacity greater than our limits and so are likely to be defective. In fact, a considerable array of commonly used techniques seem to incidentally incorporate just such an assumption of a processing capacity far in excess of most human beings.","n":0.036}}},{"i":37,"$":{"0":{"v":"larmuseauMultimodalLearningAnalytics2020","n":1}}},{"i":38,"$":{"0":{"v":"Tags","n":1}}},{"i":39,"$":{"0":{"v":"Sampling","n":1}}},{"i":40,"$":{"0":{"v":"Non Probablistic","n":0.707}}},{"i":41,"$":{"0":{"v":"Methods","n":1}}},{"i":42,"$":{"0":{"v":"Qualitative","n":1}}},{"i":43,"$":{"0":{"v":"Mixed","n":1}}},{"i":44,"$":{"0":{"v":"Learner","n":1}}},{"i":45,"$":{"0":{"v":"Perspective","n":1}}},{"i":46,"$":{"0":{"v":"Assessment","n":1}}},{"i":47,"$":{"0":{"v":"Digital","n":1},"1":{"v":"\n[[assessment.highered.digital.bearmanReimaginingUniversityAssessment2020.ch1]] argue that digital assessment is different from e-assessment, which is more concerned with 'technologized assessment'\n","n":0.25}}},{"i":48,"$":{"0":{"v":"Context Dependent","n":0.707}}},{"i":49,"$":{"0":{"v":"Assessment Triangle","n":0.707}}},{"i":50,"$":{"0":{"v":"Alignment","n":1}}},{"i":51,"$":{"0":{"v":"reasoning","n":1}}},{"i":52,"$":{"0":{"v":"jodyvance","n":1}}},{"i":53,"$":{"0":{"v":"Hopper","n":1}}},{"i":54,"$":{"0":{"v":"evidence","n":1}}},{"i":55,"$":{"0":{"v":"edci338","n":1}}},{"i":56,"$":{"0":{"v":"AEHE","n":1}}}]}
